{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEUu+LM0iDTIzan/x2+GgC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IkramKheopsys/SFA/blob/main/untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esz6_Y3zkApZ",
        "outputId": "aa2f9eca-4dc8-4e5f-aa35-78cece37a36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SFA'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 150 (delta 56), reused 70 (delta 14), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (150/150), 48.28 KiB | 1.61 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IkramKheopsys/SFA.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.chdir('SFA')\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfUIjVbHmuVy",
        "outputId": "2d1f78fc-c336-4c82-ba62-cd5830d3b626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SFA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python SFA/main.py"
      ],
      "metadata": {
        "id": "wgEQmWzpl7XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model.test_models import TextGeneration,get_embeddings\n",
        "\n",
        "\n",
        "\n",
        "file_path = 'training_data.json'\n",
        "\n",
        "\n",
        "Embedding_output = get_embeddings(file_path)\n",
        "print(\"\\n\\n\")\n",
        "print(\"Embeddings:\")\n",
        "print(Embedding_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxV1aAOfmjHw",
        "outputId": "d79c9c34-4301-4e99-840a-c886796706aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Embeddings:\n",
            "torch.Size([6, 7, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34bXq3uyv5SI",
        "outputId": "658cc119-5957-4d01-b105-9a9a4f83a5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SFA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def evaluation_metrics(predicted_vector,input_vector):\n",
        "\n",
        "  num_correct_words = 0\n",
        "  score = 0\n",
        "  # Loop over sequences in the batch\n",
        "  for i in range(predicted_vector.shape[0]):\n",
        "      predicted_sequence = predicted_vector[i]  # Get predicted sequence\n",
        "      input_sequence = input_vector[i]  # Get input sequence\n",
        "\n",
        "      # Count the number of words correctly predicted\n",
        "      for j in range(min(predicted_sequence.shape[0], input_sequence.shape[0])):\n",
        "          if predicted_sequence[j] == input_sequence[j]:\n",
        "              num_correct_words += 1\n",
        "      score =+ num_correct_words/len(input_sequence)\n",
        "  return score/predicted_vector.shape[0]\n",
        "\n",
        "predicted_vector = torch.tensor([[1, 3, 2, 4], [5, 6, 7, 8]])  # Exemple de séquences prédites\n",
        "input_vector = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 2]])  # Exemple de séquences d'entrée\n",
        "\n",
        "# Appel de la fonction d'évaluation\n",
        "num_correct = evaluation_metrics(predicted_vector, input_vector)\n",
        "print(\"Précision de position: \", num_correct)\n"
      ],
      "metadata": {
        "id": "2kUsODjDn2IW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff89845-7766-43aa-fff6-2bcad0c6e751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Précision de position:  0.625\n"
          ]
        }
      ]
    }
  ]
}